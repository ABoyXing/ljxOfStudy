# 线性回归算法

---

### 章节1: 线性回归正规方程 (8节)

- **建议**: 建议学习线性回归的基本概念及库调用，重点在理解应用和多元线性回归解决方案，跳过冗长的推导。
- **建议时间投入**: **1天**  
- **课时总计**: 118分钟（约2小时）
1. **课时01** 承前启后数据分析概要 - 2分25秒 - **重要性：低**
2. **课时02** 什么是线性回归 - 8分4秒 - **重要性：高**
3. **课时03** 线性回归基本概念 - 20分30秒 - **重要性：高**
4. **课时04** 线性回归概念更上一层楼 - 17分35秒 - **重要性：中**
5. **课时05** 正规方程 - 14分8秒 - **重要性：中**
6. **课时06** 正规方程应用求解多元一次方程 - 19分59秒 - **重要性：中**
7. **课时07** sklearn线性回归正规方程运算 - 13分32秒 - **重要性：高**
8. **课时08** sklearn带截距运算 - 22分29秒 - **重要性：低**

---

### 章节2: 多元线性回归推导 (8节)

- **建议**: 章节主要是数学推导，推荐略读，仅保留多元线性回归的基础理解。
- **建议时间投入**: **1天**  
- **课时总计**: 128分钟（约2小时10分钟）
9. **课时09** 八元一次方程问题再现 - 20分48秒 - **重要性：中**
10. **课时10** 八元一次方程增加截距求解 - 25分58秒 - **重要性：中**
11. **课时11** 正规方程推导过程 - 18分1秒 - **重要性：低**
12. **课时12** 凸函数判定 - 7分16秒 - **重要性：低**
13. **课时13** 最大似然估计 - 17分32秒 - **重要性：低**
14. **课时14** 最小二乘法公式推导 - 19分30秒 - **重要性：低**
15. **课时15** 正规方程线性回归演示 - 13分3秒 - **重要性：低**
16. **课时16** sklearn线性回归演示 - 6分32秒 - **重要性：低**

---

### 章节3: 梯度下降 (8节)

- **建议**: 梯度下降是后续深度学习的基础，重点掌握概念、步骤及实现代码。
- **建议时间投入**: **1.5天**  
- **课时总计**: 122分钟（约2小时）
17. **课时17** 波士顿房价加载与查看 - 12分10秒 - **重要性：低**
18. **课时18** 数据拆分建模与预测 - 22分43秒 - **重要性：高**
19. **课时19** 模型评估 - 19分2秒 - **重要性：中**
20. **课时20** 梯度下降概念介绍 - 16分43秒 - **重要性：高**
21. **课时21** 梯度下降步骤 - 9分14秒 - **重要性：高**
22. **课时22** 函数与导函数求解最优解 - 9分45秒 - **重要性：中**
23. **课时23** 梯度下降代码演示 - 23分17秒 - **重要性：高**
24. **课时24** 梯度下降可视化 - 9分9秒 - **重要性：低**

---

### 章节4: 梯度下降进阶 (9节)

- **建议**: 重点了解梯度下降的不同类型，理解随机与小批量梯度下降的差异性。
- **建议时间投入**: **1天**  
- **课时总计**: 122分钟（约2小时）
25. **课时25** 三种常用梯度下降介绍对比 - 10分46秒 - **重要性：高**
26. **课时26** 线性回归梯度下降更新公式 - 19分10秒 - **重要性：中**
27. **课时27** BGD批量梯度下降更新公式 - 9分15秒 - **重要性：中**
28. **课时28** SGD和MBGD更新公式 - 9分38秒 - **重要性：高**
29. **课时29** BGD批量梯度下降代码实现 - 31分37秒 - **重要性：中**
30. **课时30** BGD批量梯度下降求解多元一次方程 - 6分10秒 - **重要性：低**
31. **课时31** SGD随机梯度下降求解一元一次方程 - 19分12秒 - **重要性：低**
32. **课时32** SGD随机梯度下降求解多元一次方程 - 6分30秒 - **重要性：低**
33. **课时33** MBGD小批量梯度下降代码实现 - 6分43秒 - **重要性：低**

---

### 章节5: 梯度下降优化 (6节)

- **建议**: 归一化和正则化内容在模型应用中重要，建议重点学习。
- **建议时间投入**: **1天**  2024年11月15日
- **课时总计**: 115分钟（约2小时）
34. **课时34** 归一化目的 - 23分44秒 - **重要性：高**
35. **课时35** 最小值最大值归一化 - 18分29秒 - **重要性：中**
36. **课时36** Z-score归一化 - 14分55秒 - **重要性：高**
37. **课时37** 天池工业蒸汽量项目归一化实战（一） - 19分14秒 - **重要性：低**
38. **课时38** 天池工业蒸汽量项目归一化实战（二） - 17分51秒 - **重要性：低**
39. **课时39** 过拟合欠拟合与正则化 - 20分47秒 - **重要性：高**

---

### 章节6: 梯度下降优化进阶 (10节)

- **建议**: 推荐学习L1、L2正则化及应用，其余进阶内容可按需简化。
- **建议时间投入**: **1.5天**  
- **课时总计**: 121分钟（约2小时）
40. **课时40** 归一化内容总结重点目标值归一化 - 7分39秒 - **重要性：低**
41. **课时41** 作业 - 1分11秒 - **重要性：低**
42. **课时42** 套索回归介绍 - 11分15秒 - **重要性：低**
43. **课时43** L1正则化可视化图形 - 15分48秒 - **重要性：高**
44. **课时44** L1正则化稀松性缩小系数到0 - 15分35秒 - **重要性：中**
45. **课时45** L1正则化套索回归权重衰减梯度下降公式 - 10分2秒 - **重要性：中**
46. **课时46** L2正则化岭回归原理详解 - 16分21秒 - **重要性：高**
47. **课时47** Ridge算法使用 - 16分39秒 - **重要性：中**
48. **课时48** Lasso回归使用 - 22分47秒 - **重要性：高**
49. **课时49** ElasticNet弹性网络使用 - 6分31秒 - **重要性：低**

---

### 章节7: 线性回归升维与实战 (8节)

- **建议**: 可学习多项式回归升维的基本概念和一次实战应用，帮助理解非线性关系。
- **建议时间投入**: **1天**  
- **课时总计**: 120分钟（约2小时）
50. **课时50** 天池工业蒸汽量不同模型不同处理得分整理 - 11分12秒 - **重要性：低**

51. **课时51** 多项式回归升维概念介绍 - 10分6秒 - **重要性：中**

52. **课时52** 多项式回归升维实战（一） - 16分39秒
    
    - **重要性：中**

53. **课时53** 多项式回归升维维度概念详解 - 14分35秒 - **重要性：低**

54. **课时54** 多项式回归升维实战（二） - 13分21秒 - **重要性：低**

55. **课时55** 多项式回归实战天猫双十一销量预测（线性回归模型） - 21分10秒 - **重要性：中**

56. **课时56** 多项式回归实战天猫双十一销量预测（随机梯度下降模型） - 12分13秒 - **重要性：低**

57. **课时57** 中国人寿保费预测（EDA数据探索） - 20分6秒 - **重要性：低**

---

**总学习时间**: 约9天

# 线性分类算法

以下是基于线性分类算法课程内容的学习计划：

---

### 章节1: 逻辑回归二分类 (6节)

**建议**: 学习逻辑回归的基本概念和sigmoid函数，重点理解逻辑回归的损失函数推导与代码实现，跳过一些冗长的推导部分。
**建议时间投入**：1天 课时总计：**127分钟**

- **课时01** 逻辑回归介绍 - 重要性：高
- **课时02** Sigmoid 函数介绍 - 重要性：高
- **课时03** 逻辑回归损失函数推导 - 重要性：中
- **课时04** 损失函数立体化呈现（一） - 重要性：中
- **课时05** 损失函数立体化呈现（二） - 重要性：中
- **课时06** 逻辑回归代码实现与概率手动计算 - 重要性：高

---

### 章节2: 逻辑回归多分类softmax (7节)

**建议**: 学习多分类逻辑回归的概念与应用，理解Softmax函数和OVR思想，重点放在概率预测的代码实现上。
**建议时间投入**：1.5天 课时总计：**146分钟**

- **课时07** 逻辑回归梯度下降更新公式 - 重要性：中
- **课时08** 逻辑回归多分类OVR - 重要性：高
- **课时09** 逻辑回归OVR建模与概率预测 - 重要性：高
- **课时10** 代码实战逻辑回归OVR概率计算 - 重要性：中
- **课时11** Softmax函数与概率计算 - 重要性：高
- **课时12** 代码实战逻辑回归Softmax概率计算 - 重要性：高
- **课时13** Sigmoid与Softmax异同 - 重要性：低

---

### 章节3: SVM 支持向量机原理（一） (6节)

**建议**: 学习支持向量机的基本原理，理解目标函数的推导与最大间隔的概念，适当简化复杂的推导过程。
**建议时间投入**：1.5天 课时总计：**116分钟**

- **课时14** SVM支持向量机概念 - 重要性：高
- **课时15** 支持向量机SVM目标函数推导 - 重要性：中
- **课时16** SVM二分类最大间隔绘制 - 重要性：中
- **课时17** 拉格朗日乘子法介绍 - 重要性：中
- **课时18** 拉格朗日乘子法原理推导 - 重要性：中
- **课时19** 支持向量机SVM作业介绍 - 重要性：低

---

### 章节4: SVM支持向量机原理（二） (7节)

**建议**: 深入学习不同核函数的应用与KKT条件，重点理解核函数的数学公式与支持向量机的非线性特性。
**建议时间投入**：1.5天 课时总计：**132分钟**

- **课时20** 作业讲解和知识点回顾 - 重要性：中
- **课时21** SVC支持向量机分类不同核函数差异 - 重要性：中
- **课时22** 非线性核函数介绍 - 重要性：中
- **课时23** 核函数对应数学公式 - 重要性：中
- **课时24** KKT条件介绍 - 重要性：高
- **课时25** SVR支持向量机回归核函数差异 - 重要性：中
- **课时26** SVR支持向量机回归拟合天猫双十一销量方程 - 重要性：低

---

### 章节5: SVM支持向量机原理与实战（一） (7节)

**建议**: 学习SVM的可视化原理和KKT条件的应用，重点放在目标函数构建与损失函数的求解过程。
**建议时间投入**：1.5天 课时总计：**134分钟**

- **课时27** SVM支持向量机原理可视化 - 重要性：高
- **课时28** SVM支持向量机KKT条件详解 - 重要性：中
- **课时29** SVM支持向量机对偶问题转化 - 重要性：中
- **课时30** SVM支持向量机目标函数构建 - 重要性：中
- **课时31** SVM支持向量机损失函数SMO求解过程 - 重要性：中
- **课时32** SVM支持向量机网格搜索参数优化 - 重要性：中
- **课时33** SVM软间隔及优化 - 重要性：中

---

### 章节6: SVM支持向量机原理与实战（二） (5节)

**建议**: 进行实战案例分析，学习人脸识别等应用中的SVM模型，结合实际数据进行参数选择与优化。
**建议时间投入**：1天 课时总计：**132分钟**

- **课时34** LFW人脸数据加载与介绍 - 重要性：中
- **课时35** SVM支持向量机LFW数据建模与参数选择 - 重要性：中
- **课时36** SVM支持向量机LFW人脸分类建模预测可视化 - 重要性：中
- **课时37** SVM支持向量机软间隔与优化目标函数构建 - 重要性：中
- **课时38** SVM算法整体回顾 - 重要性：中

---

**总学习时间**: 约8.5天

---

# 聚类算法

以下是基于无监督学习算法课程内容的学习计划：

---

### 章节1: 聚类系列算法高级 (9节)

**建议**: 理解Kmeans聚类的原理和应用，学习聚类评价指标的使用，重点放在Kmeans的可视化和特征提取应用上。
**建议时间投入**：1.5天 课时总计：**151分钟**

- **课时01** Kmeans聚类亚洲国家队自动划分类别 - 重要性：高
- **课时02** Kmeans聚类亚洲国家队类别可视化 - 重要性：高
- **课时03** 聚类算法概念介绍 - 重要性：中
- **课时04** 聚类算法的划分标准 - 重要性：中
- **课时05** Kmeans算法原理和流程 - 重要性：高
- **课时06** 聚类评价指标轮廓系数 - 重要性：中
- **课时07** 轮廓系数使用 - 重要性：中
- **课时08** 聚类评价指标调整兰德系数 - 重要性：中
- **课时09** Kmeans聚类提取特征图片压缩 - 重要性：高

---

### 章节2: 聚类系列算法进阶 (9节)

**建议**: 学习DBSCAN算法及分层聚类的原理和应用，重点理解其参数设定和效果。
**建议时间投入**：1.5天 课时总计：**120分钟**

- **课时10** DBSCAN算法介绍 - 重要性：高
- **课时11** DBSCAN算法原理和参数详解 - 重要性：高
- **课时12** DBSCAN聚类案例数据创建 - 重要性：中
- **课时13** DBSCAN聚类案例Kmeans算法聚类效果 - 重要性：中
- **课时14** DBSCAN聚类案例效果 - 重要性：中
- **课时15** 分层聚类概念原理参数介绍 - 重要性：高
- **课时16** 分层聚类概念原理参数介绍 - 重要性：中
- **课时17** 分层聚类瑞士卷数据效果 - 重要性：中
- **课时18** 作业介绍和知识点总结 - 重要性：低

---

### 章节3: 降维系列算法高级 (6节)

**建议**: 学习数据降维的概念与方法，重点理解PCA算法及其实现，学习相关性分析和SVD。
**建议时间投入**：1.5天 课时总计：**118分钟**

- **课时19** 数据相关性概念介绍和代码演示 - 重要性：中
- **课时20** 数据降维概念 - 重要性：中
- **课时21** 数据降维方法介绍 - 重要性：低
- **课时22** PCA 算法介绍和使用 - 重要性：高
- **课时23** PCA降维算法特征值分解代码实现 - 重要性：高
- **课时24** PCA降维算法奇异值分解SVD代码实现 - 重要性：高

---

### 章节4: 降维系列算法进阶 (7节)

**建议**: 深入学习LDA与NMF算法的原理与实现，重点放在线性代数相关知识的理解与应用。
**建议时间投入**：1.5天 课时总计：**114分钟**

- **课时25** 协方差和散度矩阵 - 重要性：中
- **课时26** 线性代数之特征值特征向量分解 - 重要性：中
- **课时27** 线性代数之SVD奇异值分解 - 重要性：中
- **课时28** LDA算法原理 - 重要性：高
- **课时29** LDA算法流程 - 重要性：高
- **课时30** NMF非负矩阵分解 - 重要性：中
- **课时31** LDA算法流程（修正） - 重要性：中

---

### 章节5: EM算法与GMM高斯混合模型 (8节)

**建议**: 学习EM算法与GMM的原理及其应用，重点理解其思想与步骤，以及在实际问题中的应用案例。
**建议时间投入**：1.5天 课时总计：**138分钟**

- **课时32** LLE局部线性嵌入降维法算法原理介绍 - 重要性：中
- **课时33** LLE算法使用代码举例 - 重要性：中
- **课时34** EM算法思想与步骤 - 重要性：高
- **课时35** 极大似然思想 - 重要性：中
- **课时36** EM算法入门举例介绍 - 重要性：中
- **课时37** EM算法进阶举例介绍 - 重要性：中
- **课时38** GMM高斯混合模型聚类使用代码举例 - 重要性：高
- **课时39** Jessen不等式介绍 - 重要性：低

---

**总学习时间**: 约8天

---

# 决策树算法

以下是基于决策树系列算法课程内容的学习计划：

---

### 章节1: 决策树分类算法原理 (8节)

**建议**: 理解决策树的基本概念与应用，重点放在信息熵与Gini系数的计算上，并学习可视化工具的使用。
**建议时间投入**：1.5天 课时总计：**99分钟**

- **课时01** 决策树概述示例一（债务偿还） - 重要性：中
- **课时02** 决策树概述示例二（找对象） - 重要性：中
- **课时03** 决策树的应用和可视化 - 重要性：高
- **课时04** 决策树graphviz安装与可视化 - 重要性：中
- **课时05** 信息熵和信息增益概念和公式 - 重要性：高
- **课时06** 手写代码计算信息熵 - 重要性：高
- **课时07** 手写代码计算信息熵对比不同属性信息增益 - 重要性：中
- **课时08** 作业-手写代码计算Gini系数 - 重要性：中

---

### 章节2: 决策树分类算法进阶 (6节)

**建议**: 深入学习决策树的根节点选择、剪枝和超参数选择。
**建议时间投入**：1.5天 课时总计：**122分钟**

- **课时09** 决策树原理：代码筛选决策树的根节点 - 重要性：高
- **课时10** 决策树分类指标详解 - 重要性：中
- **课时11** 决策树鸢尾花分类案例 - 重要性：高
- **课时12** 决策树剪枝详解 - 重要性：高
- **课时13** 决策树超参数选择 - 重要性：中
- **课时14** 决策树作业葡萄酒分类不同算法比较 - 重要性：低

---

### 章节3: 决策树回归算法 (7节)

**建议**: 理解决策回归树的原理和裂分条件，学习如何与其他算法比较。
**建议时间投入**：1.5天 课时总计：**138分钟**

- **课时15** 决策树与不同算法综合对比 - 重要性：中
- **课时16** 决策回归树原理概述 - 重要性：高
- **课时17** 决策回归树算法示例演示 - 重要性：高
- **课时18** 决策回归树原理未分裂mse计算 - 重要性：中
- **课时19** 决策回归树原理根节点裂分mse计算 - 重要性：高
- **课时20** 决策回归树裂分条件计算 - 重要性：中
- **课时21** 作业-归一化对不同算法有何影响 - 重要性：低

---

### 章节4: 集成算法 (5节)

**建议**: 学习集成算法的原理，包括随机森林与极限森林的应用。
**建议时间投入**：1天 课时总计：**110分钟**

- **课时22** 归一化对不同算法影响 - 重要性：低
- **课时23** 决策回归树VS线性回归 - 重要性：中
- **课时24** 集成算法原理概述 - 重要性：高
- **课时25** 随机森林原理和应用 - 重要性：高
- **课时26** 极限森林原理和应用 - 重要性：高

---

### 章节5: GBDT梯度提升分类树高级 (6节)

**建议**: 深入理解GBDT的原理与应用，关注交叉熵的介绍和GBDT的数学公式。
**建议时间投入**：1天 课时总计：**114分钟**

- **课时27** 极限森林随机性之所在 - 重要性：中
- **课时28** 信息熵 - 重要性：中
- **课时29** 交叉熵原理概述 - 重要性：高
- **课时30** GBDT梯度提升分类树使用 - 重要性：高
- **课时31** GBDT梯度提升分类树数学公式 - 重要性：高
- **课时32** GBDT算例建模与可视化 - 重要性：中

---

### 章节6: GBDT梯度提升分类树进阶 (10节)

**建议**: 进一步分析GBDT的实现，学习如何拟合树并计算损失函数。
**建议时间投入**：2天 课时总计：**204分钟**

- **课时33** GBDT原理剖析代码拟合第一棵树 - 重要性：高
- **课时34** GBDT原理剖析代码拟合第二棵树 - 重要性：中
- **课时35** GBDT原理剖析代码拟合第三棵树 - 重要性：中
- **课时36** GBDT原理剖析代码计算概率 - 重要性：高
- **课时37** GBDT交叉熵损失函数介绍 - 重要性：高
- **课时38** GBDT交叉熵损失函数化简 - 重要性：中
- **课时39** GBDT交叉熵损失函数求导 - 重要性：中
- **课时40** GBDT初始值F0的推导过程 - 重要性：中
- **课时41** GBDT叶节点预测值公式推导 - 重要性：高
- **课时42** GBDT二分类算法步骤总结 - 重要性：中

---

### 章节7: GBDT梯度提升回归树 (6节)

**建议**: 理解GBDT回归树的原理与应用，重点在裂分条件的计算。
**建议时间投入**：1.5天 课时总计：**93分钟**

- **课时43** 集成算法概述 - 重要性：中
- **课时44** bagging集成算法代码演示 - 重要性：中
- **课时45** GBDT梯度提升回归树概述 - 重要性：高
- **课时46** GBDT梯度提升回归树应用 - 重要性：高
- **课时47** GBDT梯度提升回归树原理 - 重要性：高
- **课时48** GBDT梯度提升回归树裂分条件计算 - 重要性：高

---

### 章节8: Adaboost提升树二分类算法高级 (4节)

**建议**: 学习Adaboost算法的原理与应用案例，重点放在多分类应用上。
**建议时间投入**：0.5天 课时总计：**84分钟**

- **课时49** Adaboost算法原理概述 - 重要性：高
- **课时50** Adaboost算法应用乳腺癌案例 - 重要性：高
- **课时51** Adaboost算法应用多分类案例 - 重要性：中
- **课时52** Adaboost算法应用多分类数据清洗案例 - 重要性：中

---

### 章节9: Adaboost提升树二分类算法进阶 (7节)

**建议**: 深入学习Adaboost的流程与实现，重点在代码构建及聚合方法。
**建议时间投入**：1天 课时总计：**134分钟**

- **课时53** Adaboost二分类算法流程讲解 - 重要性：高
- **课时54** Adaboost数据建模以及可视化 - 重要性：中
- **课时55** Adaboost代码构建第一棵树拆分条件计算 - 重要性：高
- **课时56** Adaboost代码构建第一棵树弱学习器权重计算以及样本权重更新 - 重要性：中
- **课时57** Adaboost代码构建第二棵决策树 - 重要性：中
- **课时58** Adaboost代码构建第三棵决策树 - 重要性：中
- **课时59** Adaboost弱学习器聚合 - 重要性：中

---

### 章节10: Adaboost提升树多分类算法与回归算法 (6节)

**建议**: 学习Adaboost在多分类和回归中的应用，理解二分类概率的计算。
**建议时间投入**：1天 课时总计：**122分钟**

- **课时60** Adaboost二分类概率代码演示计算 - 重要性：高
- **课时61** Adaboost提升树多分类建模预测 - 重要性：高
- **课时62** Adaboost多分类代码构建第一棵树 - 重要性：中
- **课时63** Adaboost多分类代码构建第二棵树 - 重要性：中
- **课时64** Adaboost多分类代码构建第三棵树 - 重要性：中
- **课时65** Adaboost多分类概率代码演示计算 - 重要性：中

---

### 章节11: Xgboost算法与实战 (12节)

**建议**: 深入学习XGBoost的实现与参数调优，掌握实战中的应用。
**建议时间投入**：2天 课时总计：**265分钟**

- **课时66** Adaboost回归算法建模和算法流程 - 重要性：中
- **课时67** Adaboost回归树算法原理代码构建 - 重要性：中
- **课时68** XGBoost算法介绍 - 重要性：高
- **课时69** XGBoost树结构 - 重要性：高
- **课时70** XGBoost目标函数方程 - 重要性：高
- **课时71** XGBoost目标函数泰勒展开 - 重要性：高
- **课时72** XGBoost目标函数优化 - 重要性：高
- **课时73** XGBoost叶节点权重计算公式推导 - 重要性：高
- **课时74** XGBoost三种建模方式介绍 - 重要性：高
- **课时75** XGBoost实战建模与二分类评价指标ROC-AUC介绍 - 重要性：高
- **课时76** XGBoost实战超参数选择 - 重要性：高
- **课时77** XGBoost实战参数测试验证 - 重要性：中

---

### 总结

**总学习时间**：约**13天** (建议每天学习3小时，涵盖课程内容和实践作业)。具体安排可根据自己的学习进度和时间灵活调整。每个章节结束后，可进行小结与实践，以加深理解与记忆。
